{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Frame Manipulation**\n",
    "## Once you have frame, you can do whatever you want with the frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Read video and play\n",
    "---\n",
    "1. cv2.VideoCapture(): VideoCapture constructors, with or without parameter\n",
    ">- cv2.VideoCapture(**filename**): opened video file or image sequence\n",
    ">- cv2.VideoCapture(**device**): device ID\n",
    "\n",
    "2. videocapture.read(): Grabs, decodes and returns the next video frame. returns a bool (True/False). If frame is read correctly, it will be True.\n",
    ">- first return value: grabbed or not (true or false)\n",
    ">- second return value: grabbed frame\n",
    "\n",
    "3. cv2.cvtColor(src, code[, dst[, dstCn]]): Converts an image from one color space to another\n",
    ">- **src**: input image\n",
    ">- dst: output image of the same size and depth as src\n",
    ">- **code**: color space conversion code\n",
    ">- dstCn: number of channels in the destination image\n",
    "\n",
    "4. VideoCapture.release(): Closes video file or capturing device\n",
    "\n",
    "5. cap.get() cap.set():  You can also access some of the **features of this video** using **cap.get(propId)** method where propId is a number from 0 to 18. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280.0 720.0\n",
      "7.8125e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "## read video as play\n",
    "#put it to memory\n",
    "cap = cv2.VideoCapture('/media/junhui/DATA/Videos/SampleVideo_1280x720_1mb.mp4')  \n",
    "print(cap.get(3), cap.get(4))  # get the width and height of this video\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()    #read frame by frame\n",
    "    \n",
    "    if ret:    #if frame is grabbed(true)\n",
    "        # Frame manipulation \n",
    "        grayFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)     \n",
    "    #Frame manipulation \n",
    "    cv2.imshow('frame', grayFrame)   #if grabbed, show it        \n",
    "    \n",
    "    #waitKey(25): display frame by every 25 milliseconds\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):  \n",
    "        break\n",
    "        \n",
    "cap.release()    # Closes video file or capturing device\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Read video and save frame by frame\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('/media/junhui/DATA/Videos/SampleVideo_1280x720_1mb.mp4')\n",
    "\n",
    "frame, image = cap.read()\n",
    "count = 0\n",
    "\n",
    "while frame:   # if grabbed\n",
    "    # save frame as JPEG file\n",
    "    cv2.imwrite(\"./video2frame/frame%d.jpeg\" % count, image)     \n",
    "    \n",
    "    frame, image = cap.read()\n",
    "    #print('Read a new frame: ', frame)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\"\"\"\n",
    " My way of saving frames\n",
    "\"\"\"\n",
    "\n",
    "cap = cv2.VideoCapture('/media/junhui/DATA/Videos/SampleVideo_1280x720_1mb.mp4')\n",
    "count = 0\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        # save frames. Frame manipulation \n",
    "        cv2.imwrite(\"./video2frame/frame%d.jpeg\" % count, frame) \n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    #\n",
    "    if not ret:\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Capture video by camera\n",
    "---\n",
    "1. cv2.VideoWriter([filename, fourcc, fps, frameSize[, isColor]]): \n",
    " - Parameters:\n",
    ">- filename: Name of the output video file\n",
    ">- fourcc:  **4-character code of codec** used to **compress the frames**.\n",
    ">- fps:  Framerate of the created video stream.\n",
    ">- frameSize: Size of the video frames.\n",
    ">- isColor: If it is not zero, the encoder will expect and encode color frames, otherwise it will work with grayscale frames (the flag is currently supported on Windows only).\n",
    "\n",
    " - The constructors/functions initialize video writers. On Linux **FFMPEG** is used to write videos; on Windows FFMPEG or VFW is used; on MacOSX QTKit is used.\n",
    " \n",
    "2. A **video codec** is an **electronic circuit** or **software** that **compresses or decompresses** digital video. It converts uncompressed video to a compressed format or vice versa. In the context of video compression, **\"codec\" is a concatenation of \"encoder\" and \"decoder\"**---a device that only compresses is typically called an encoder, and one that only decompresses is a decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)  \n",
    "\n",
    "# only if you want to save the stream\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  #('X','V','I','D)\n",
    "out = cv2.VideoWriter('./outputByCamera.avi', fourcc, 40.0, (640,480))  #\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()   # get frames\n",
    "    \n",
    "    if ret == True:\n",
    "        \"\"\"\n",
    "        Real-time Frame manipulation\n",
    "        \"\"\"\n",
    "        frameFlipped = cv2.flip(frame, 0)   # (0, 1, -1)\n",
    "        out.write(frameFlipped) #write the flipped frame\n",
    "        cv2.imshow('frame',frameFlipped)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Read frames as a video\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re\n",
    "\n",
    "## put frames into memory. FIX the order!!\n",
    "images = []\n",
    "framePath = './video2frame/'\n",
    "\n",
    "for f in os.listdir(framePath):\n",
    "    if f.endswith('.jpeg'):\n",
    "        images.append(f)\n",
    "\n",
    "## get the width and height channels of the first frame\n",
    "imgPath = os.path.join(framePath, images[0])\n",
    "frame = cv2.imread(imgPath)\n",
    "cv2.imshow('video', frame)\n",
    "height, width, channels = frame.shape\n",
    "\n",
    "height, width, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract the number from file name\n",
    "\"\"\"\n",
    "def cvtStr2Int(imgName):\n",
    "    strName = imgName.split(\".\")[0]\n",
    "    p = re.compile(r'\\d+')\n",
    "    numName = p.findall(strName)\n",
    "    intName = int(numName[0])\n",
    "    \n",
    "    return intName\n",
    "\n",
    "\"\"\"\n",
    "Sort and construct new name\n",
    "\"\"\"\n",
    "def sortFrameName(images):\n",
    "    front = 'frame'\n",
    "    end = '.jpeg'\n",
    "    \n",
    "    newImages = []\n",
    "    mlist = [cvtStr2Int(i) for i in images]\n",
    "    mlist.sort()\n",
    "    \n",
    "    \n",
    "    for i in mlist:\n",
    "        seq = [front, str(i), end]\n",
    "        newImages.append(\"\".join(seq))\n",
    "    \n",
    "    return newImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sortFrameName(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show frames one by one\n",
    "for image in images:\n",
    "    imgPath = os.path.join(framePath, image)\n",
    "    frame = cv2.imread(imgPath)\n",
    "    \n",
    "    cv2.imshow('video', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 6) show frames in the right order and save as a video(.avi)\n",
    "\n",
    "* The use of argpaser package\n",
    "[example here](http://tsaith.github.io/combine-images-into-a-video-with-python-3-and-opencv-3.html)\n",
    "* Sort frames in the right order\n",
    "[Check here for more information](https://pastebin.com/YbAq2UvF)\n",
    "\n",
    "* Run the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame files have been sorted\n",
      "The output video is output.avi\n"
     ]
    }
   ],
   "source": [
    "!python frame2video.py -ext jpeg -o output.avi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
